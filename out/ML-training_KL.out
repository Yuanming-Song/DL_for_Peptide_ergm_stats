no change     /opt/apps/anaconda/2024.06/condabin/conda
no change     /opt/apps/anaconda/2024.06/bin/conda
no change     /opt/apps/anaconda/2024.06/bin/conda-env
no change     /opt/apps/anaconda/2024.06/bin/activate
no change     /opt/apps/anaconda/2024.06/bin/deactivate
no change     /opt/apps/anaconda/2024.06/etc/profile.d/conda.sh
no change     /opt/apps/anaconda/2024.06/etc/fish/conf.d/conda.fish
no change     /opt/apps/anaconda/2024.06/shell/condabin/Conda.psm1
no change     /opt/apps/anaconda/2024.06/shell/condabin/conda-hook.ps1
no change     /opt/apps/anaconda/2024.06/lib/python3.12/site-packages/xontrib/conda.xsh
no change     /opt/apps/anaconda/2024.06/etc/profile.d/conda.csh
no change     /data/homezvol3/yuanmis1/.bashrc
No action taken.
Raw train labels: 0    0.135036496350365,0.14963503649635,0.086678832...
1    0.00478468899521531,0.050580997949419,0.408065...
2    0,0,0.246865203761755,0.524294670846395,0.2288...
3    0.00748299319727891,0.00136054421768707,0.1693...
4    0.0645161290322581,0.162903225806452,0.1177419...
Name: Label, dtype: object
Raw valid labels: 0    0,0.0175131348511384,0.182136602451839,0.35989...
1    0,0.023876404494382,0.141151685393258,0.693117...
2    0.131656804733728,0,0.267011834319527,0.446005...
3    0,0,0,0.745310957551826,0.107601184600197,0.14...
4    0.0717875089734386,0.24934194783441,0.43359655...
Name: Label, dtype: object
Raw test labels: 0          0,0,0,0,0.730232558139535,0.269767441860465
1    0.245145631067961,0,0,0.298543689320388,0.2257...
2    0,0,0.385286783042394,0,0.613466334164589,0.00...
3          0,0,0,0.820683903252711,0.179316096747289,0
4    0.421290322580645,0.213225806451613,0.14,0.110...
Name: Label, dtype: object
Processed train labels: tensor([[1.3504e-01, 1.4964e-01, 8.6679e-02, 2.7281e-01, 2.6734e-01, 8.8504e-02],
        [4.7847e-03, 5.0581e-02, 4.0807e-01, 1.5038e-01, 3.6774e-01, 1.8455e-02],
        [2.0000e-08, 2.0000e-08, 2.4687e-01, 5.2429e-01, 2.2884e-01, 2.0000e-08],
        [7.4830e-03, 1.3606e-03, 1.6939e-01, 4.5918e-01, 3.6190e-01, 6.8029e-04],
        [6.4516e-02, 1.6290e-01, 1.1774e-01, 4.8871e-01, 6.4516e-03, 1.5968e-01]])
Processed valid labels: tensor([[2.0000e-08, 1.7513e-02, 1.8214e-01, 3.5989e-01, 3.7653e-01, 6.3923e-02],
        [2.0000e-08, 2.3876e-02, 1.4115e-01, 6.9312e-01, 1.4115e-01, 7.0227e-04],
        [1.3166e-01, 2.0000e-08, 2.6701e-01, 4.4601e-01, 6.5089e-02, 9.0237e-02],
        [2.0000e-08, 2.0000e-08, 2.0000e-08, 7.4531e-01, 1.0760e-01, 1.4709e-01],
        [7.1788e-02, 2.4934e-01, 4.3360e-01, 2.3187e-01, 1.3400e-02, 2.0000e-08]],
       device='cuda:0')
Processed test labels: tensor([[2.0000e-08, 2.0000e-08, 2.0000e-08, 2.0000e-08, 7.3023e-01, 2.6977e-01],
        [2.4515e-01, 2.0000e-08, 2.0000e-08, 2.9854e-01, 2.2573e-01, 2.3058e-01],
        [2.0000e-08, 2.0000e-08, 3.8529e-01, 2.0000e-08, 6.1347e-01, 1.2469e-03],
        [2.0000e-08, 2.0000e-08, 2.0000e-08, 8.2068e-01, 1.7932e-01, 2.0000e-08],
        [4.2129e-01, 2.1323e-01, 1.4000e-01, 1.1032e-01, 1.0161e-01, 1.3548e-02]],
       device='cuda:0')
Epoch 1/50:
  Train Loss: 0.554020
  Valid KL: 0.561904
  Avg Gradient Norm: 0.161821
  Avg Parameter Norm: 4229.775879
  Learning Rate: 0.500000
  ---
Saved best model with Valid KL: 0.561904 at /dfs9/tw/yuanmis1/mrsec/ML-MD-Peptide/DL_for_Peptide/Transformer_KL_rebin_best.pt
Epoch 2/50:
  Train Loss: 0.557262
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 1882.648560
  Learning Rate: 0.500000
  ---
Epoch 3/50:
  Train Loss: 0.557031
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 767.595581
  Learning Rate: 0.500000
  ---
Epoch 4/50:
  Train Loss: 0.491298
  Valid KL: 0.490730
  Avg Gradient Norm: 0.000739
  Avg Parameter Norm: 3285.142090
  Learning Rate: 0.500000
  ---
Saved best model with Valid KL: 0.490730 at /dfs9/tw/yuanmis1/mrsec/ML-MD-Peptide/DL_for_Peptide/Transformer_KL_rebin_best.pt
Epoch 5/50:
  Train Loss: 0.540863
  Valid KL: 0.566939
  Avg Gradient Norm: 0.087693
  Avg Parameter Norm: 6214.823242
  Learning Rate: 0.500000
  ---
Epoch 6/50:
  Train Loss: 0.587671
  Valid KL: 0.566939
  Avg Gradient Norm: 0.045411
  Avg Parameter Norm: 8564.787109
  Learning Rate: 0.500000
  ---
Epoch 7/50:
  Train Loss: 0.562844
  Valid KL: 0.566939
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 8726.718750
  Learning Rate: 0.500000
  ---
Epoch 8/50:
  Train Loss: 0.562838
  Valid KL: 0.566939
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 3559.975098
  Learning Rate: 0.500000
  ---
Epoch 9/50:
  Train Loss: 0.562497
  Valid KL: 0.566939
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 1451.401611
  Learning Rate: 0.500000
  ---
Epoch 10/50:
  Train Loss: 0.578318
  Valid KL: 0.566939
  Avg Gradient Norm: 0.370050
  Avg Parameter Norm: 1965.180420
  Learning Rate: 0.500000
  ---
Epoch 11/50:
  Train Loss: 0.650528
  Valid KL: 0.669284
  Avg Gradient Norm: 41.076775
  Avg Parameter Norm: 10120.398438
  Learning Rate: 0.500000
  ---
Epoch 12/50:
  Train Loss: 0.623001
  Valid KL: 0.573262
  Avg Gradient Norm: 0.234951
  Avg Parameter Norm: 7482.038086
  Learning Rate: 0.500000
  ---
Epoch 13/50:
  Train Loss: 0.568969
  Valid KL: 0.566939
  Avg Gradient Norm: 0.000001
  Avg Parameter Norm: 6932.582031
  Learning Rate: 0.500000
  ---
Epoch 14/50:
  Train Loss: 0.545805
  Valid KL: 0.490730
  Avg Gradient Norm: 0.002302
  Avg Parameter Norm: 3300.903564
  Learning Rate: 0.500000
  ---
Epoch 15/50:
  Train Loss: 0.495224
  Valid KL: 0.490730
  Avg Gradient Norm: 1.163024
  Avg Parameter Norm: 4873.818359
  Learning Rate: 0.500000
  ---
Epoch 16/50:
  Train Loss: 0.489735
  Valid KL: 0.490730
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 4296.179688
  Learning Rate: 0.500000
  ---
Epoch 17/50:
  Train Loss: 0.489731
  Valid KL: 0.490730
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 1751.556030
  Learning Rate: 0.500000
  ---
Epoch 18/50:
  Train Loss: 0.522708
  Valid KL: 0.669284
  Avg Gradient Norm: 0.322261
  Avg Parameter Norm: 2607.800537
  Learning Rate: 0.500000
  ---
Epoch 19/50:
  Train Loss: 0.667329
  Valid KL: 0.669284
  Avg Gradient Norm: 0.026989
  Avg Parameter Norm: 9355.423828
  Learning Rate: 0.500000
  ---
Epoch 20/50:
  Train Loss: 0.628244
  Valid KL: 0.561904
  Avg Gradient Norm: 2.697495
  Avg Parameter Norm: 8682.830078
  Learning Rate: 0.500000
  ---
Epoch 21/50:
  Train Loss: 0.566067
  Valid KL: 0.677634
  Avg Gradient Norm: 0.003055
  Avg Parameter Norm: 8249.634766
  Learning Rate: 0.500000
  ---
Epoch 22/50:
  Train Loss: 0.666042
  Valid KL: 0.677634
  Avg Gradient Norm: 0.003431
  Avg Parameter Norm: 6546.487305
  Learning Rate: 0.500000
  ---
Epoch 23/50:
  Train Loss: 0.649436
  Valid KL: 0.669284
  Avg Gradient Norm: 2.244420
  Avg Parameter Norm: 3813.471680
  Learning Rate: 0.500000
  ---
Epoch 24/50:
  Train Loss: 0.625032
  Valid KL: 0.561904
  Avg Gradient Norm: 0.094688
  Avg Parameter Norm: 10013.456055
  Learning Rate: 0.500000
  ---
Epoch 25/50:
  Train Loss: 0.558608
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000145
  Avg Parameter Norm: 5437.638672
  Learning Rate: 0.500000
  ---
Epoch 26/50:
  Train Loss: 0.557125
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 2219.837402
  Learning Rate: 0.500000
  ---
Epoch 27/50:
  Train Loss: 0.556948
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 905.056519
  Learning Rate: 0.500000
  ---
Epoch 28/50:
  Train Loss: 0.625810
  Valid KL: 0.677634
  Avg Gradient Norm: 0.278984
  Avg Parameter Norm: 5151.444824
  Learning Rate: 0.500000
  ---
Epoch 29/50:
  Train Loss: 0.547632
  Valid KL: 0.677634
  Avg Gradient Norm: 0.004197
  Avg Parameter Norm: 5183.841797
  Learning Rate: 0.500000
  ---
Epoch 30/50:
  Train Loss: 0.490967
  Valid KL: 0.490730
  Avg Gradient Norm: 0.228225
  Avg Parameter Norm: 5507.736328
  Learning Rate: 0.500000
  ---
Epoch 31/50:
  Train Loss: 0.490113
  Valid KL: 0.490730
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 2450.422363
  Learning Rate: 0.500000
  ---
Epoch 32/50:
  Train Loss: 0.490078
  Valid KL: 0.490730
  Avg Gradient Norm: 0.000015
  Avg Parameter Norm: 1011.758240
  Learning Rate: 0.500000
  ---
Epoch 33/50:
  Train Loss: 0.554395
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000479
  Avg Parameter Norm: 2695.713867
  Learning Rate: 0.500000
  ---
Epoch 34/50:
  Train Loss: 0.557060
  Valid KL: 0.561904
  Avg Gradient Norm: 0.068210
  Avg Parameter Norm: 4482.279785
  Learning Rate: 0.500000
  ---
Epoch 35/50:
  Train Loss: 0.556837
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 5617.922363
  Learning Rate: 0.500000
  ---
Epoch 36/50:
  Train Loss: 0.557076
  Valid KL: 0.561904
  Avg Gradient Norm: 0.002479
  Avg Parameter Norm: 3886.076416
  Learning Rate: 0.500000
  ---
Epoch 37/50:
  Train Loss: 0.557037
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 2686.796143
  Learning Rate: 0.500000
  ---
Epoch 38/50:
  Train Loss: 0.556968
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000010
  Avg Parameter Norm: 1114.088013
  Learning Rate: 0.500000
  ---
Epoch 39/50:
  Train Loss: 0.559593
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000103
  Avg Parameter Norm: 587.365356
  Learning Rate: 0.500000
  ---
Epoch 40/50:
  Train Loss: 0.557093
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000099
  Avg Parameter Norm: 1029.532959
  Learning Rate: 0.500000
  ---
Epoch 41/50:
  Train Loss: 0.556925
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 521.124084
  Learning Rate: 0.500000
  ---
Epoch 42/50:
  Train Loss: 0.557568
  Valid KL: 0.561904
  Avg Gradient Norm: 0.003862
  Avg Parameter Norm: 431.968597
  Learning Rate: 0.500000
  ---
Epoch 43/50:
  Train Loss: 0.557074
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 5046.406738
  Learning Rate: 0.500000
  ---
Epoch 44/50:
  Train Loss: 0.557093
  Valid KL: 0.561904
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 2138.938721
  Learning Rate: 0.500000
  ---
Epoch 45/50:
  Train Loss: 0.577523
  Valid KL: 0.669284
  Avg Gradient Norm: 0.009374
  Avg Parameter Norm: 1688.547729
  Learning Rate: 0.500000
  ---
Epoch 46/50:
  Train Loss: 0.645370
  Valid KL: 0.669284
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 2680.328125
  Learning Rate: 0.500000
  ---
Epoch 47/50:
  Train Loss: 0.567268
  Valid KL: 0.566939
  Avg Gradient Norm: 0.000010
  Avg Parameter Norm: 1096.579712
  Learning Rate: 0.500000
  ---
Epoch 48/50:
  Train Loss: 0.562787
  Valid KL: 0.566939
  Avg Gradient Norm: 0.000264
  Avg Parameter Norm: 483.894073
  Learning Rate: 0.500000
  ---
Epoch 49/50:
  Train Loss: 0.562831
  Valid KL: 0.566939
  Avg Gradient Norm: 0.000000
  Avg Parameter Norm: 763.279663
  Learning Rate: 0.500000
  ---
Epoch 50/50:
  Train Loss: 0.562886
  Valid KL: 0.566939
  Avg Gradient Norm: 0.000001
  Avg Parameter Norm: 315.944183
  Learning Rate: 0.500000
  ---
Test KL Divergence: 0.492714
